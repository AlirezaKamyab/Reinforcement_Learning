{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a4c040-e98a-4ed4-9f2f-236bbc78cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787165c-b590-40da-bd1b-6f49fe02785b",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5507117-b041-440e-9de7-40b1c891fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenLake:\n",
    "    def __init__(\n",
    "        self, \n",
    "        max_steps:int=16, \n",
    "        is_slippery:bool=True, \n",
    "        render:bool=True, \n",
    "        custom_reward: bool=True\n",
    "    ):\n",
    "        self.max_steps = max_steps\n",
    "        self.render = render\n",
    "        self.custom_reward = custom_reward\n",
    "        self.frozen_lake = gym.make(\n",
    "            'FrozenLake-v1',\n",
    "            desc=None,\n",
    "            map_name=\"4x4\",\n",
    "            is_slippery=is_slippery,\n",
    "            render_mode='rgb_array' if render else None\n",
    "        )\n",
    "\n",
    "    def generate_episode(\n",
    "        self, \n",
    "        policy: np.ndarray, \n",
    "        exploration:bool=True\n",
    "    ):\n",
    "        state, _ = self.frozen_lake.reset()\n",
    "        reward = 0.0\n",
    "        trajectory = []\n",
    "        # Render RGB trajectory to observe the states visually\n",
    "        if self.render:\n",
    "            render = [self.frozen_lake.render()]\n",
    "            \n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            if exploration:\n",
    "                action = np.random.choice([0, 1, 2, 3], p=policy[state])\n",
    "            else:\n",
    "                action = np.argmax(policy[state])\n",
    "            \n",
    "            new_state, new_reward, terminated, _, _ = self.frozen_lake.step(action)\n",
    "            if self.custom_reward:\n",
    "                x = int(new_state / 4)\n",
    "                y = new_state % 4\n",
    "                if (x != 3 or y != 3) and terminated:\n",
    "                    new_reward = -25\n",
    "                else:\n",
    "                    new_reward = -np.sqrt((x-3)**2 + (y-3)**2)\n",
    "\n",
    "            trajectory.append({'reward':reward, 'state':state, 'action':action})\n",
    "\n",
    "            # Render RGB trajectory to observe the states visually\n",
    "            if self.render:\n",
    "                render.append(self.frozen_lake.render())\n",
    "                \n",
    "            reward = new_reward\n",
    "            state = new_state\n",
    "\n",
    "            if self.max_steps <= len(trajectory) - 1:\n",
    "                break\n",
    "\n",
    "        trajectory.append({'reward':reward})\n",
    "        if self.render:\n",
    "            return trajectory, render\n",
    "        return trajectory\n",
    "\n",
    "    def generate_video(\n",
    "        self,\n",
    "        policy:np.ndarray,\n",
    "        output_name:str='output.mp4',\n",
    "        fps:float=1.5\n",
    "    ):\n",
    "        _, frames = self.generate_episode(policy=policy, exploration=False)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_writer = cv2.VideoWriter(output_name, fourcc, fps, (256, 256))\n",
    "        for frame in frames:\n",
    "            frame = frame[:, :, ::-1]\n",
    "            video_writer.write(frame)\n",
    "        video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c69e1-7521-4950-bb23-97616ded531f",
   "metadata": {},
   "source": [
    "## On-policy Monte Carlo Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2d0bdd-327c-4bae-b874-e8c421a53223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                             | 54/5000 [00:00<00:17, 285.37it/s, G=-26.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean return is -35.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████▉                       | 1027/5000 [00:04<00:17, 226.27it/s, G=-9.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean return is -17.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████▋                 | 2023/5000 [00:08<00:13, 214.72it/s, G=-9.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean return is -6.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████▋           | 3044/5000 [00:13<00:09, 211.57it/s, G=-9.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean return is -4.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████▎     | 4023/5000 [00:18<00:04, 211.59it/s, G=-9.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean return is -3.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 5000/5000 [00:22<00:00, 222.91it/s, G=-13.08]\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.1\n",
    "num_actions = 4\n",
    "state_set = 16\n",
    "gamma = 0.9\n",
    "render_every_episodes = 1000\n",
    "episodes = 5000\n",
    "policy = np.ones([state_set, num_actions], dtype=np.float32) * epsilon / num_actions\n",
    "policy[:, 0] = 1 - epsilon + epsilon / num_actions \n",
    "Q = np.zeros([state_set, num_actions], dtype=np.float32)\n",
    "N = np.zeros([state_set, num_actions], dtype=np.float32)\n",
    "mean_G = 0.0\n",
    "frozen_lake = FrozenLake(is_slippery=False, custom_reward=True)\n",
    "\n",
    "with tqdm(range(episodes)) as prog:\n",
    "    for episode in prog:\n",
    "        trajectory, frames = frozen_lake.generate_episode(policy=policy, exploration=True)\n",
    "        G = 0.0\n",
    "\n",
    "        for i in reversed(range(len(trajectory) - 1)):\n",
    "            reward = trajectory[i + 1]['reward']\n",
    "            state = trajectory[i]['state']\n",
    "            action = trajectory[i]['action']\n",
    "            G = gamma * G + reward\n",
    "\n",
    "            is_visited = any([t['state'] == state and t['action'] == action for t in trajectory[:i]])\n",
    "            if not is_visited:\n",
    "                state, action = int(state), int(action)\n",
    "                N[state, action] += 1\n",
    "                Q[state, action] = Q[state, action] + (1 / N[state, action]) * (G - Q[state, action])\n",
    "                greedy_action = np.argmax(Q[state])\n",
    "                for a in range(num_actions):\n",
    "                    if a == greedy_action:\n",
    "                        policy[state, a] = 1 - epsilon + epsilon / num_actions\n",
    "                    else:\n",
    "                        policy[state, a] = epsilon / num_actions\n",
    "\n",
    "        mean_G = mean_G + (1 / (episode + 1)) * (G - mean_G)\n",
    "        if episode % render_every_episodes == 0:\n",
    "            frozen_lake.generate_video(policy, fps=2, output_name=f'output_{episode}.mp4')\n",
    "            print(f'mean return is {mean_G:>3.2f}')\n",
    "            mean_G = 0.0\n",
    "\n",
    "        prog.set_postfix({'G': f'{G:>2.2f}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd3473-80f0-44a9-9352-dad1f879abaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
